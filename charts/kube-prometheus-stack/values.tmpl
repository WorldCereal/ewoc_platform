alertmanager:
  enabled: true
  apiVersion: v2
  ingress:
    enabled: false

  alertmanagerSpec:
    nodeSelector:
      role: kong

  
grafana:
  enabled: true
  defaultDashboardsEnabled: true
  nodeSelector:
    role: kong
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard

      annotations: {}

  ingress:
    enabled: false
  
  grafana.ini: 
    log:
      mode: "console"
      level: "info"
    log.frontend:
      enabled: true
    server:
      domain: grafana.VALUE_HOSTNAME
      root_url: https://grafana.VALUE_HOSTNAME
    auth:
      oauth_auto_login: true
      disable_login_form: true
      signout_redirect_url: https://auth.VALUE_HOSTNAME/realms/worldcereal/protocol/openid-connect/logout?redirect_uri=https%3A%2F%2Fgrafana.ewoc-prod.hexdump.ovh
      
    auth.generic_oauth:
      enabled: true
      tls_skip_verify_insecure: true
      allow_sign_up: true
      client_id: grafana
      scopes: profile
      auth_url: https://auth.VALUE_HOSTNAME/realms/worldcereal/protocol/openid-connect/auth
      token_url: https://auth.VALUE_HOSTNAME/realms/worldcereal/protocol/openid-connect/token
      api_url: https://auth.VALUE_HOSTNAME/realms/worldcereal/protocol/openid-connect/userinfo
      #role_attribute_path: contains(roles[*], 'admin') && 'Admin' || contains(roles[*], 'editor') && 'Editor' || 'Viewer'
      role_attribute_strict: false
      client_secret: GRAFANA_CS
prometheus:
  enabled: true
  
  prometheusSpec:
    podMonitorSelectorNilUsesHelmValues: true
    serviceMonitorSelectorNilUsesHelmValues: true
    serviceMonitorSelector:
      matchLabels:
        release: kube-prometheus-stack
    nodeSelector:
      role: kong
    retention: 2d
    
    storageSpec: 
     volumeClaimTemplate:
       spec:
         #storageClassName: standard
         accessModes: ["ReadWriteOnce"]
         resources:
           requests:
             storage: 10Gi

    replicas: 1

    ## Interval between consecutive scrapes.
    ## Defaults to 30s.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/release-0.44/pkg/prometheus/promcfg.go#L180-L183
    ##
    scrapeInterval: "60s"


    ## Interval between consecutive evaluations.
    ##
    evaluationInterval: "60s"

    ## EXPERIMENTAL: Number of shards to distribute targets onto.
    ## Number of replicas multiplied by shards is the total number of Pods created.
    ## Note that scaling down shards will not reshard data onto remaining instances, it must be manually moved.
    ## Increasing shards will not reshard data either but it will continue to be available from the same instances.
    ## To query globally use Thanos sidecar and Thanos querier or remote write data to a central location.
    ## Sharding is done on the content of the `__address__` target meta-label.
    ##
    shards: 1

    resources:
      limits:
        memory: 8192Mi
      requests:
        memory: 4096Mi
  ingress:
    enabled: false

prometheusOperator:
  enabled: true
  hostNetwork: false        
  nodeSelector:
    role: kong

kubelet:
  enabled: true
  namespace: kube-system
  serviceMonitor:
    ## Enable scraping /metrics/resource from kubelet's service
    ## This is disabled by default because container metrics are already exposed by cAdvisor
    ##
    resource: true